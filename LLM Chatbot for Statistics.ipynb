{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a9062a-0a08-45e4-99b9-05f3e5eeb7e8",
   "metadata": {},
   "source": [
    "# Statistics ChatBot LLM\n",
    "***This LLM chatbot has two attitudes to determine whether a question is basic or advanced and responds accordingly.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bcd0261d-c6ea-4e6a-a34e-eed8783e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student asks hypothesis tests\n",
    "#\"What's mean and variance?\"\n",
    "#\"In which cases we apply Chi-Square?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8eede056-f549-46a6-99ec-02d87b340e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c5f970-ffbb-4cbb-9505-2a483c644bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Burk\\\\Desktop\\\\Folders\\\\openai api.txt\"\n",
    "api_key = open(path).read()\n",
    "basic_question_template = \"\"\"You are a statistics teacher who is to understand terms.You assume no prior knowledge.Here is your question : \\n{input}\"\"\"\n",
    "advanced_question_template = \"\"\"You are a statistics professor who explains to advanced audiance members.You can assume anyone you answer has a PhD\n",
    "in Statistics.Here's your question : \\n{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1963b743-d72a-4c87-aae2-1885ec504deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\" : \"basic statistics\",\n",
    "        \"description\" : \"Answers basic statistics questions\",\n",
    "        \"template\" : basic_question_template\n",
    "    ,},\n",
    "    {\n",
    "        \"name\":\"advanced statistics\",\n",
    "        \"description\" : \"Answers advanced statistics questions\",\n",
    "        \"template\" : advanced_question_template,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "069d48f2-4d5b-4c9e-af54-362afcd4530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "llm = ChatOpenAI(api_key = api_key)\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name=p_info['name']\n",
    "    prompt_template = p_info['template']\n",
    "    prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "    chain = LLMChain(llm=llm,prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ad6af14-c752-4460-be88-327d454ae050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "destinations = [f\"{p['name']} : {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec997eb8-9678-4bcc-b45f-cd356341ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "basic statistics: {'input': \"What's mean and variance?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Mean is a measure of central tendency that represents the average value of a dataset. It is calculated by adding up all the values in the dataset and dividing by the total number of values.\n",
      "\n",
      "Variance is a measure of dispersion that represents how spread out the values in a dataset are from the mean. It is calculated by taking the average of the squared differences between each value and the mean. A higher variance indicates that the values in the dataset are more spread out, while a lower variance indicates that the values are closer to the mean.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(template=router_template,\n",
    "                              input_variables = ['input'],\n",
    "                              output_parser = RouterOutputParser())\n",
    "router_chain = LLMRouterChain.from_llm(llm,router_prompt)\n",
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                        destination_chains = destination_chains,\n",
    "                        default_chain=default_chain,verbose=True)\n",
    "print(chain.run(\"What's mean and variance?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef0bbbf4-e903-44ed-9e99-3aa9b30f4aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "advanced statistics: {'input': 'In which cases do we apply the Chi-Square test?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The Chi-Square test is typically used in the following cases:\n",
      "\n",
      "1. To determine if there is a significant association between two categorical variables.\n",
      "2. To test for independence between two categorical variables.\n",
      "3. To compare observed frequencies with expected frequencies in a contingency table.\n",
      "4. To assess goodness of fit between observed data and expected data in a hypothesis test.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"In which cases we apply Chi-Square?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
